import pandas as pd
import numpy as np
import json, os
from pycocotools import mask as cocomask
import cv2
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import matplotlib as mpl

# -----------------------------
# Utilities for Building DataFrames
# -----------------------------

def findCategory(data):
    # find categories
    cats = data["categories"]
    category = pd.DataFrame(cats)
    category = category.drop(['supercategory'], axis=1)
    category = category.rename(columns={'id': 'category_id'})
    return category

def findImages(data):
    img = data["images"]
    images = pd.DataFrame(img)

    # unwanted columns exist if exported from CVAT. Not if generated by my code
    if set(['license','flickr_url','coco_url','date_captured']).issubset(images.columns):
        images = images.drop(columns=['license','flickr_url','coco_url','date_captured'])

    return images

def findAnnotations(data):
    anno = data["annotations"]
    df = pd.DataFrame(anno)
    return df

def cleanForJson(category=None, df=None):
    # clean category for json dump
    if category is not None:
        category = category.rename(columns={'category_id': 'id'})
        category['supercategory'] = ""

    # add columns in df for json dump
    if df is not None:
        df['iscrowd'] = 0
        df['attributes'] = [{'occluded':False}] * len(df['id'])
        cols = ['id', 'image_id', 'category_id', 'segmentation', 'area', 'bbox', 'iscrowd', 'attributes']
        df = df[cols + [c for c in df.columns if c not in cols]]
        # remove file_name column in df if it exists
        df = drop_columns_if_exist(df,columns=['file_name', 'file_name_x', 'file_name_y'])

    return category, df

def createDF(filename):
    with open(filename, 'r') as file:
        data = json.load(file)

        category = findCategory(data)
        images = findImages(data)
        nos_image = images['id'].max()
        df = findAnnotations(data)
        df = df.merge(images[['id','file_name']], left_on='image_id', right_on='id')
        df = df.rename(columns={'id_x': 'id'})
        df = drop_columns_if_exist(df,columns=['iscrowd','attributes','id_y'])
        return category, images, df

def drop_columns_if_exist(df, columns):
    df = df.copy()
    for col in columns:
        if col in df.columns:
            df = df.drop(columns=col)
    return df

# if categories aren't supposed to be the same
# category 1 and df are the ones you want to change
def fix_category_id(category1, category2, df, df2):
    
    category_name = pd.concat([category1['name'], category2['name']], ignore_index = True)      # combine category 1 and 2
    unique_category_names = category_name.unique()                                              # Get unique category names
    # Create a new DataFrame with these unique category names and a new column for the relisted category_id
    category_new = pd.DataFrame({
        'category_id': range(1, len(unique_category_names) + 1),
        'name': unique_category_names
    })

    category1 = category1.merge(category_new, on='name', how='left')        # map category_id to category1 and category 2
    category2 = category2.merge(category_new, on='name', how='left')        # map category_id to category1 and category 2

    # use new category_id to replace old category_id in df
    df = df.merge(category1[['category_id_x', 'category_id_y']], left_on='category_id', right_on='category_id_x', how='left')
    df2 = df2.merge(category2[['category_id_x', 'category_id_y']], left_on='category_id', right_on='category_id_x', how='left')
    df = df.drop(columns=['category_id', 'category_id_x']).rename(columns={'category_id_y': 'category_id'})
    df2 = df2.drop(columns=['category_id', 'category_id_x']).rename(columns={'category_id_y': 'category_id'})

    return category_new, df, df2

# convert all np.integer, np.floating and np.ndarray into json recognisable int, float and lists
class NpEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, np.integer):
            return int(obj)
        if isinstance(obj, np.floating):
            return float(obj)
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        return json.JSONEncoder.default(self, obj)

# bbox and mask utilities
def process_bbox(box):
    x1, y1, x2, y2 = box['x1'], box['y1'], box['x2'], box['y2']
    bbox = [x1, y1, x2-x1, y2-y1]       # x,y,w,h in COCO format
    bbox = [round(x,2) for x in bbox]
    return bbox

def process_segment(segment):
    xs = segment['x']
    ys = segment['y']
    assert len(xs) == len(ys), "Length of xs and ys do not match"
    segment_list = []
    for i in range(len(xs)):
        segment_list.extend([round(xs[i],2), round(ys[i],2)])
    return [segment_list]

def calculate_area(coords):
    coords = coords[0]      # segmentation in [[x1,y1,x2,y2,...]] format
    x = coords[::2]
    y = coords[1::2]
    area = 0.5 * abs(sum(x[j]*y[j+1] - x[j+1]*y[j] for j in range(-1, len(x)-1)))
    area = round(area,2)
    return area

# -----------------------------
# Utilities for plotting
# -----------------------------
# This is built using OpenCV so images can be plotted without the use of object detection architectures/their API

def new_plot(image_path, df, category, file_name, plot_RGB=True):
    # Assuming image_path is the path to your image
    image = cv2.imread(image_path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    # Get image dimensions
    height, width, _ = image.shape
    # Create a new figure with a single subplot and set figure size to match image dimensions
    dpi = 300
    fig, ax = plt.subplots(1, figsize=(width / dpi, height / dpi), dpi=dpi)
    cmap = mpl.colormaps['tab10']

    # Display the image
    if plot_RGB:
        ax.imshow(image)
    else:
        bg_black = np.zeros_like(image)
        ax.imshow(bg_black)

    # Assuming df is your DataFrame and it has columns 'bbox' for bounding boxes, 'segmentation' for masks, 'category_id' for category labels, and 'score' for confidence scores
    for i, row in df.iterrows():
        if plot_RGB:
            plot_color = cmap(row['category_id'])      # same colour for the same category
            plot_alpha = 0.4

            # Draw bounding box
            bbox = row['bbox']
            rect = patches.Rectangle((bbox[0], bbox[1]), bbox[2], bbox[3], linewidth=1, edgecolor=plot_color, facecolor='none')    # params: (x,y), width, height
            ax.add_patch(rect)
        else:
            plot_color = 'white'
            plot_alpha = 1

        # Draw mask
        for mask in row['segmentation']:
            mask = np.array(mask)               # Convert the list to a numpy array
            poly = patches.Polygon(mask.reshape(-1, 2), fill=True, color=plot_color, alpha=plot_alpha)
            ax.add_patch(poly)
        # mask = row['segmentation'][0]
        # mask = np.array(mask)               # Convert the list to a numpy array
        # poly = patches.Polygon(mask.reshape(-1, 2), fill=True, color=plot_color, alpha=0.4)
        # ax.add_patch(poly)

        # Add label and score
        # label = f"score: {row['score']:.2f}" if 'score' in row else ''
        if plot_RGB:
            category_name = category[category['category_id'] == row['category_id']]['name'].values[0]
            if 'score' in row:
                label = f"{category_name}: {row['score']:.2f}"
            else:
                label = category_name
            plt.text(bbox[0], bbox[1], label, color='white', fontsize=4, bbox=dict(facecolor=plot_color, edgecolor=plot_color, boxstyle='square,pad=0'))

    ax.axis('off')
    plt.savefig(file_name, bbox_inches='tight', pad_inches=0, dpi=dpi)  # Save the plot as an image
    plt.close(fig)

# -------------------
# Util for converting between masks and polygons
# -------------------

def mask_to_polygon(maskedArr, multiply=True):
    """
    Convert a mask in a binary matrix of shape (H, W) to a polygon.
    Args:
        maskedArr (np.array): a binary matrix of shape (H,W) that contains True/False value
    Returns:
        segmentation[0] (np.array): an array of the polygon. [x1, y1, x2, y2...]
        area (float): the size of the polygon
        bbox (list): Bounding box coordinates in COCO format [x_min, y_min, delta_x, delta_y].
    """
    # Convert the binary mask to a binary image (0 and 255 values)
    if multiply:
        binary_image = maskedArr.astype(np.uint8) * 255
    else:
        binary_image = maskedArr.astype(np.uint8)

    # Find contours in the binary image
    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # Retrieve the polygon coordinates for each contour
    polygons = []
    for contour in contours:
        if contour.size >= 6:
            polygons.append(contour.flatten().tolist())
        # polygon = contour.squeeze().tolist()
        # polygons.append(polygon)
    # Calculate areas and bbox
    area = np.sum(maskedArr)
    if area == 0:
        return None, 0, None
    else:    
        bboxes = [polygon_to_bbox(p) for p in polygons]
        # bbox = find_remasked_bbox(maskedArr)
        return polygons, area, bboxes

def find_remasked_bbox(mask):
    """
    Find the bounding box that fits the resized mask.

    Args:
        mask (np.array): Resized mask of shape (H', W').
        original_shape (tuple): Shape of the original image or mask (H, W).

    Returns:
        list: Bounding box coordinates in COCO format [x_min, y_min, delta_x, delta_y].
    """
    # Find the minimum and maximum coordinates that enclose the mask region
    rows = np.any(mask, axis=1)
    cols = np.any(mask, axis=0)
    y_min, y_max = np.where(rows)[0][[0, -1]]
    x_min, x_max = np.where(cols)[0][[0, -1]]

    return [x_min, y_min, x_max-x_min, y_max-y_min]

def polygon_to_bbox(polygons):
    xs = polygons[::2]
    ys = polygons[1::2]
    x_min = min(xs)
    x_max = max(xs)
    y_min = min(ys)
    y_max = max(ys)
    return [x_min, y_min, x_max - x_min, y_max - y_min]

# Functions to combine segmentation masks
def polygon_to_mask(polygons, height, width):
    '''
    Args:
        polygon (list): in [[...]]
        height, width (int): height and width of image
    Returns:
        np.array: a mask of shape (H, W)
    '''
    the_mask = np.zeros((height, width), dtype=np.uint8)

    # tackle the problem of having >1 polygon in an instance
    if len(polygons) > 1:
        for poly in polygons:
            # poly = np.array(poly).reshape((-1, 2))
            rles = cocomask.frPyObjects([poly], height, width)
            a_mask = np.squeeze(cocomask.decode(rles))
            # print(a_mask.shape)
            the_mask = np.logical_or(the_mask, a_mask)
    else:
        rles = cocomask.frPyObjects(polygons, height, width)
        the_mask = np.squeeze(cocomask.decode(rles))

    return the_mask

def create_json(masks_df, category_list, image_dir, json_name):
    # Create the image df
    images_unique = masks_df['image'].unique()
    h_unique, w_unique = [], []
    for x in images_unique:
        height, width = cv2.imread(os.path.join(image_dir, x)).shape[:2]
        h_unique.append(height)
        w_unique.append(width)
    images_gen = pd.DataFrame({'file_name':images_unique, 'width':w_unique, 'height':h_unique})
    images_gen = images_gen.sort_values(by='file_name').reset_index(drop=True)
    images_gen.insert(0,'id',images_gen.index+1)

    # create categories df
    category_unique = category_list
    category_gen = pd.DataFrame({'id':range(1,len(category_unique)+1), 'name':category_unique, 'supercategory':""})

    # create defects df
    # masks_df['mask'] = masks_df['mask'].apply(lambda x: x[0])
    # masks_df['segmentation'], masks_df['area'], masks_df['bbox'] = zip(*masks_df['mask'].map(mask_to_polygon))     # convert mask to polygon - already done at SAM output
    df_gen = masks_df[['image','category','bbox','segmentation','area', 'score']]	
    df_gen = df_gen.merge(images_gen[['id', 'file_name']], left_on='image', right_on='file_name', how='left')      # merge images_gen to get image_id
    df_gen = df_gen.rename(columns={'id':'image_id'})
    df_gen = df_gen.merge(category_gen[['id', 'name']], left_on='category', right_on='name', how='left')    # merge category_gen to get category_id
    df_gen = df_gen.rename(columns={'id':'category_id'})
    # df_gen['score'] = df_gen['score'].apply(lambda x: x[0])         # convert the score from list to float - already done at SAM output
    df_gen = df_gen.sort_values(by='image_id').reset_index(drop=True)
    df_gen.insert(0,'id',df_gen.index+1)
    df_gen = df_gen.drop(columns=['file_name','category','name'])
    df_gen = df_gen[['id', 'image_id', 'category_id', 'segmentation', 'area', 'bbox', 'score']]      # reorder the columns
    # df_gen = clean_vertices(images_gen, df_gen)
    category_gen, df_gen = cleanForJson(category_gen, df_gen)

    # Write categories, images and annotations as arrays containing individual entries as a dictionary
    # see https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_dict.html for to_dict styles
    dict_to_json = {
        "categories": category_gen.to_dict('records'),
        "images": images_gen.to_dict('records'),
        "annotations": df_gen.to_dict('records')
        }

    with open(json_name, "w") as outfile:
        json.dump(dict_to_json, outfile, cls=NpEncoder)